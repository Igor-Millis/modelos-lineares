[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Modelos Lineares",
    "section": "",
    "text": "Bem-vindos ao meu primeiro quarto book"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "2¬† Introdu√ß√£o",
    "section": "",
    "text": "Agrade√ßo mais uma vez por toda disponibilidade, ambi√ß√£o e carinho dispostos por toda a equipe que comp√µem os projetos organizados pela Curso-R. Vamos mudar a comunidade."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "3¬† Summary",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. ‚ÄúLiterate Programming.‚Äù Comput.\nJ. 27 (2): 97‚Äì111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "prefacio.html",
    "href": "prefacio.html",
    "title": "3¬† Pref√°cio",
    "section": "",
    "text": "Agrade√ßo mais uma vez por toda disponibilidade, ambi√ß√£o e carinho dispostos por toda a equipe que comp√µem os projetos organizados pela Curso-R. Vamos mudar a comunidade."
  },
  {
    "objectID": "pag1.html",
    "href": "pag1.html",
    "title": "3¬† Motiva√ß√£o",
    "section": "",
    "text": "Uma das formas de materializar (Marx? üëÄ) a rela√ß√£o entre duas vari√°veis e criar predi√ß√µes e brincar com os dados √© contruir um modelo linear."
  },
  {
    "objectID": "pag2.html",
    "href": "pag2.html",
    "title": "4¬† Regress√£o x Classifica√ß√£o",
    "section": "",
    "text": "Existem dois tipos de problemas dentro da √°rea que vamos abordar, problemas de regress√£o e problemas de classifica√ß√£o classifica√ß√£o. A nomeclatura n√£o leva em conta a forma de resolu√ß√£o dos problemas."
  },
  {
    "objectID": "pag2.html#problemas-de-classifica√ß√£o",
    "href": "pag2.html#problemas-de-classifica√ß√£o",
    "title": "4¬† Regress√£o x Classifica√ß√£o",
    "section": "4.2 Problemas de Classifica√ß√£o",
    "text": "4.2 Problemas de Classifica√ß√£o\nY √© uma vari√°vel categ√≥rica\npodemos usar m√©todos de regress√£o para problemas de classifica√ß√£o tamb√©m"
  },
  {
    "objectID": "pag3.html",
    "href": "pag3.html",
    "title": "5¬† Nomeclaturas",
    "section": "",
    "text": "Para possibilitar um conte√∫do coeso o glos√°rio abaixo vai explicar termos t√≠picos e que ser√£o bastante usados daqui em diante"
  },
  {
    "objectID": "pag3.html#observado-versus-esperado",
    "href": "pag3.html#observado-versus-esperado",
    "title": "5¬† Nomeclaturas",
    "section": "5.2 Observado versus Esperado",
    "text": "5.2 Observado versus Esperado\nvalor observado: \\(Y\\) (ou verdade ou truth)\nvalor esperado: ≈∂ (ou predi√ß√£o ou estimado ou fitted)"
  },
  {
    "objectID": "pag3.html#erro-ou-res√≠duo",
    "href": "pag3.html#erro-ou-res√≠duo",
    "title": "5¬† Nomeclaturas",
    "section": "5.3 Erro ou Res√≠duo",
    "text": "5.3 Erro ou Res√≠duo\n√â a rela√ß√£o entre o valor observado e o valor esperado\nEm problemas de regess√£o: \\(Y -\\) ≈∂\nEm problemas de classifica√ß√£o: \\(log(≈∂) - log(1-≈∂)\\)"
  },
  {
    "objectID": "pag3.html#rela√ß√£o-entre-esperado-observado-e-o-modelo",
    "href": "pag3.html#rela√ß√£o-entre-esperado-observado-e-o-modelo",
    "title": "7¬† Nomeclaturas",
    "section": "7.4 Rela√ß√£o entre Esperado, Observado e o Modelo",
    "text": "7.4 Rela√ß√£o entre Esperado, Observado e o Modelo\n\\(≈∂ = f(x)\\) que √© o valor que a fun√ß√£o \\(f\\) retorna\n\\(≈∂\\) √© predi√ß√£o"
  },
  {
    "objectID": "pag3.html#rela√ß√£o-entre-valor-esperado-e-o-modelo",
    "href": "pag3.html#rela√ß√£o-entre-valor-esperado-e-o-modelo",
    "title": "5¬† Nomeclaturas",
    "section": "5.4 Rela√ß√£o entre Valor Esperado e o Modelo",
    "text": "5.4 Rela√ß√£o entre Valor Esperado e o Modelo\n\\(≈∂ = f(x)\\)\n≈∂ √© a predi√ß√£o"
  },
  {
    "objectID": "pag4.html",
    "href": "pag4.html",
    "title": "6¬† Infer√™ncia e Predi√ß√£o",
    "section": "",
    "text": "Para facilitar o entendimento sobre modelos √© importante explicitar a diferen√ßa entre os objetivos e inten√ß√µes entre Predi√ß√£o e Infer√™ncia"
  },
  {
    "objectID": "pag4.html#infer√™ncia",
    "href": "pag4.html#infer√™ncia",
    "title": "6¬† Infer√™ncia e Predi√ß√£o",
    "section": "6.2 Infer√™ncia",
    "text": "6.2 Infer√™ncia\nEm infer√™ncia estamos mais interessado em entender a rela√ß√£o entre as vari√°veis explicativas X e a vari√°vel resposta Y\nObjetivo inferencial:\nQuais preditores s√£o importantes? Qual a rela√ß√£o entre cada preditor e a vari√°vel resposta? Qual o efeito da mudan√ßa de valor de um dos preditores na vari√°vel resposta?\n\nAlguns rechos retirados de Aprendizado de M√°quina, Uma Abordagem Estat√≠stica p√°gina 8."
  },
  {
    "objectID": "pag5.html",
    "href": "pag5.html",
    "title": "7¬† Regress√£o Linear Simples",
    "section": "",
    "text": "Poder√≠amos escolher uma reta a m√£o para tentar descrever a rela√ß√£o entre \\(X\\) e \\(Y\\)\n\nlibrary(ggplot2)\n\nWarning: package 'ggplot2' was built under R version 4.1.2\n\np <- ggplot(data = mtcars, mapping = aes(x = mpg,\n                                    y = drat))+\n  geom_point()+\n  labs(x=\"mpg\", y=\"drat\",\n       title=\"Reta Escolhida a M√£o\")\n  \np + geom_hline(yintercept = 4)\n\n\n\n\nPor√©m, √© poss√≠vel ver que escolhendo a m√£o n√£o temos certeza sobre a ‚Äúefici√™ncia‚Äù da reta. Para n√£o lidarmos com esse problema, vamos utilizar o m√©todo da regress√£o linear simples\n\nlibrary(ggplot2)\n\np <- ggplot(data = mtcars, mapping = aes(x = mpg,\n                                    y = drat))+\n  geom_point()+\n  labs(x=\"mpg\", y=\"drat\",\n       title=\"Reta Escolhida pelo M√©todo de Regress√£o\")\n\np + geom_smooth(method = \"lm\", col = 'lightblue')+\n  labs(title=\"Modelo de Regress√£o Linear Simples\")\n\n`geom_smooth()` using formula 'y ~ x'"
  },
  {
    "objectID": "pag5.html#o-que-√©-esse-m√©todo",
    "href": "pag5.html#o-que-√©-esse-m√©todo",
    "title": "7¬† Regress√£o Linear Simples",
    "section": "7.2 O que √© esse m√©todo",
    "text": "7.2 O que √© esse m√©todo\nRegress√£o linear simples √© o m√©todo de escolha da melhor reta dentre todas as poss√≠veis de serem escolhidas\n\\(y ‚âà Œ≤_0+Œ≤_1x\\)\nO sinal ‚âà pode ser entendido como ‚Äú\\(y\\) √© aproximadamente modelado como ‚Ä¶‚Äù"
  },
  {
    "objectID": "pag5.html#no-r",
    "href": "pag5.html#no-r",
    "title": "7¬† Regress√£o Linear Simples",
    "section": "7.3 No R",
    "text": "7.3 No R\n\nView(mtcars)\n\nmelhor_reta<- lm(mpg ~ drat, data = mtcars)\nmelhor_reta\n\n\nCall:\nlm(formula = mpg ~ drat, data = mtcars)\n\nCoefficients:\n(Intercept)         drat  \n     -7.525        7.678"
  },
  {
    "objectID": "pag5.html#o-que-garante-que-essa-√©-a-melhor-reta",
    "href": "pag5.html#o-que-garante-que-essa-√©-a-melhor-reta",
    "title": "7¬† Regress√£o Linear Simples",
    "section": "7.4 O que garante que essa √© a melhor reta?",
    "text": "7.4 O que garante que essa √© a melhor reta?\nQueremos a reta que erre menos\nUm dos m√©todos √© o Root Mean Squared Error\nRMSE = \\(\\frac{1}{N} \\times \\sqrt{‚àë(y_i‚àí(Œ≤_0+Œ≤_1x))^2}\\)\nOu seja, precisamos encontrar o \\(Œ≤_1\\) e \\(Œ≤_0\\) que retornem o menor valor para RMSE.\nCom \\(Œ≤_1\\) e \\(Œ≤_0\\) sendo\n\\(Œ≤_1 = \\frac{‚àë(x_i‚àíx)(y_i‚àíy)}{‚àë(x_i-x)2}\\)\n\\(Œ≤_0=y‚àíŒ≤_1x\\)\nEsse \\(Œ≤_0\\) e \\(Œ≤_1\\) vieram de um m√©todo conhecido como Erro Quadr√°tico M√©dio. E j√° que vieram do EQM, podemos chamar \\(Œ≤_0\\) e \\(Œ≤_1\\) de Estimadores do M√≠nimos Quadrados."
  },
  {
    "objectID": "pag2.html#problemas-de-regerss√£o",
    "href": "pag2.html#problemas-de-regerss√£o",
    "title": "4¬† Regress√£o x Classifica√ß√£o",
    "section": "4.1 Problemas de regerss√£o",
    "text": "4.1 Problemas de regerss√£o\nY √© uma vari√°vel cont√≠nua"
  },
  {
    "objectID": "pag3.html#gerais",
    "href": "pag3.html#gerais",
    "title": "5¬† Nomeclaturas",
    "section": "5.1 Gerais",
    "text": "5.1 Gerais\n\\(x_1, x_2, x_3, ‚Ä¶, x_n\\) s√£o vari√°veis explicativas (ou features, ou preditores)\n\\(X\\) √© o conjunto de todas as features (\\(x_1, x_2, ‚Ä¶, x_n\\))\n\\(Y\\) √© a vari√°vel respota (ou dependente)\n\\(≈∂\\) √© o valor esperado (ou predi√ß√£o ou valor estimado)\n\\(f(x)\\) √© o modelo ou hip√≥tese"
  },
  {
    "objectID": "pag4.html#predi√ß√£o",
    "href": "pag4.html#predi√ß√£o",
    "title": "6¬† Infer√™ncia e Predi√ß√£o",
    "section": "6.1 Predi√ß√£o",
    "text": "6.1 Predi√ß√£o\nEm muitas situa√ß√µes X est√° dispon√≠vel facilmente mas, Y n√£o √© f√°cil de descobrir. (Ou mesmo n√£o √© poss√≠vel descobr√≠-lo). Queremos que ≈∂ = \\(f(x)\\) seja uma boa estimativa.\nObjetivo preditivo:\nComo podemos criar uma fun√ß√£o que tenha bom poder preditivo? Isto √©, como criar essa fun√ß√£o tal que, dadas novas observa√ß√µes , tenhamos ainda bons resultados"
  },
  {
    "objectID": "pag6.html",
    "href": "pag6.html",
    "title": "8¬† Teste de Hip√≥tese e Valor-p",
    "section": "",
    "text": "Hip√≥tese do pesquisador:\n\n‚ÄúAssassinatos n√£o est√£o relacionados com a propor√ß√£o de popula√ß√£o urbana de uma cidade.‚Äù\n\nTradu√ß√£o da hip√≥tese em termos matem√°ticos:\n\\(H_0:Œ≤_1=0\\) vs \\(H_1:Œ≤_1‚â†0\\)\nSe a hip√≥tese for verdade, ent√£o o \\(Œ≤_1\\) deveria ser zero. Por√©m, os dados disseram que \\(Œ≤_1=0.02\\).\n0.02 √© diferente de 0.00?\nSa√≠da do R\n\n## \n## Call:\n## lm(formula = Murder ~ UrbanPop, data = USArrests)\n## \n## Residuals:\n##    Min     1Q Median     3Q    Max \n## -6.537 -3.736 -0.779  3.332  9.728 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)  \n## (Intercept)  6.41594    2.90669   2.207   0.0321 *\n## UrbanPop     0.02093    0.04333   0.483   0.6312  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 4.39 on 48 degrees of freedom\n## Multiple R-squared:  0.00484,    Adjusted R-squared:  -0.01589 \n## F-statistic: 0.2335 on 1 and 48 DF,  p-value: 0.6312"
  },
  {
    "objectID": "pag5.html#o-que-√©-ser-a-melhor-reta",
    "href": "pag5.html#o-que-√©-ser-a-melhor-reta",
    "title": "7¬† Regress√£o Linear Simples",
    "section": "7.4 O que √© ser a melhor reta?",
    "text": "7.4 O que √© ser a melhor reta?\nQueremos a reta que erre menos\nUm dos m√©todos √© o Root Mean Squared Error\nRMSE = \\(\\frac{1}{N} \\times \\sqrt{‚àë(y_i‚àí(Œ≤_0+Œ≤_1x))^2}\\)\nOu seja, precisamos encontrar o \\(Œ≤_1\\) e \\(Œ≤_0\\) que retornem o menor valor para RMSE.\nCom \\(Œ≤_1\\) e \\(Œ≤_0\\) sendo\n\\(Œ≤_1 = \\frac{‚àë(x_i‚àíx)(y_i‚àíy)}{‚àë(x_i-x)2}\\)\n\\(Œ≤_0=y‚àíŒ≤_1x\\)\nEsse \\(Œ≤_0\\) e \\(Œ≤_1\\) vieram de um m√©todo conhecido como Erro Quadr√°tico M√©dio. E j√° que vieram do EQM, podemos chamar \\(Œ≤_0\\) e \\(Œ≤_1\\) de Estimadores do M√≠nimos Quadrados."
  }
]